\begin{answer}
    Note that for a uniform distribution $\sum_{x\in\cal X}\hat P(x)\log\hat P(x) = -\log m.$
    Hence we have
    $$
    \begin{aligned}
        D_{KL}(\hat P\|P_\theta) &=  \sum_{x\in\cal X} \hat P(x)\log \frac{\hat P(x)}{P_\theta(x)}\\
        &= \sum_{x\in\cal X}\hat P(x)\log\hat P(x) - \sum_{x\in\cal X}\hat P(x)\log P_\theta(x)\\
        &= -\log m - \sum_{i=1}^m \log P_\theta(x)
    \end{aligned}
    $$
    Thus, minimizing the KL divergence is equivalent to maximizing $P_{\theta}.$	
    
\end{answer}
